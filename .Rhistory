xlab = "Observation", ylab = "y",
main = "Simulated Data with Quantile Estimates",
ylim = range(c(y, eta_linear)))
# =============================================================================
# Main Results PDF
# =============================================================================
#pdf("inference_iq_v4_results.pdf", width = 14, height = 10)
par(mfrow = c(2, 2), mar = c(4, 4, 2.5, 1))
# Plot 1: Simulated data with quantile estimates
# eta = mu0[q] + X*beta[q,] + H*gamma[q,] (full linear predictor)
eta_linear <- matrix(NA, m, n)
for (q in 1:m) {
eta_linear[q, ] <- mu0_MAP[q] + as.numeric(X_design %*% beta_MAP[q, ]) +
as.vector(H %*% gamma_MAP[q, ])
}
# Get the significant block range from gamma_result
df_gamma <- gamma_result$detected_blocks
sig_blocks <- which(df_gamma$significant_bh)
# Find the observation with max deviation from predictive median within the significant block
# Sign-aware: only consider positive residuals if gamma > 0, negative if gamma < 0
signal_obs <- NA
if (length(sig_blocks) > 0) {
# Get the first significant block
first_sig_block <- sig_blocks[1]
block_start <- df_gamma$obs_start[first_sig_block]
block_end <- df_gamma$obs_end[first_sig_block]
block_obs <- block_start:block_end
# Get the gamma for this block and determine its sign
# gamma_samples is (n_iter x m x r), take mean across iterations and quantiles
gamma_block <- gamma_samples[, , first_sig_block]  # n_iter x m
gamma_mean <- mean(gamma_block)  # overall mean gamma for this block
gamma_sign <- sign(gamma_mean)
# Compute residuals: y - predictive_median (not absolute)
# Median quantile is tau = 0.5 (index 3 for quintuple quantiles)
median_idx <- which.min(abs(taus - 0.5))
residuals <- y[block_obs] - eta_linear[median_idx, block_obs]
# Filter residuals based on gamma sign
if (gamma_sign > 0) {
# Positive shift: only consider positive residuals
valid_idx <- which(residuals > 0)
} else if (gamma_sign < 0) {
# Negative shift: only consider negative residuals
valid_idx <- which(residuals < 0)
} else {
# If gamma is exactly 0, use all residuals (fallback)
valid_idx <- seq_along(residuals)
}
if (length(valid_idx) > 0) {
# Find the observation with maximum absolute deviation among valid ones
deviations <- abs(residuals[valid_idx])
max_dev_idx <- valid_idx[which.max(deviations)]
signal_obs <- block_obs[max_dev_idx]
}
cat("Signal selection info:\n")
cat("  Block", first_sig_block, "- gamma mean:", round(gamma_mean, 4),
"sign:", gamma_sign, "\n")
cat("  Valid residuals:", length(valid_idx), "out of", length(block_obs), "\n")
if (!is.na(signal_obs)) {
cat("  Selected signal obs:", signal_obs, "with residual:",
round(y[signal_obs] - eta_linear[median_idx, signal_obs], 4), "\n\n")
}
}
# Set up point colors - all gray except signal point
point_colors <- rep("gray50", n)
if (!is.na(signal_obs)) {
point_colors[signal_obs] <- "darkgreen"
}
plot(1:n, y, type = "p", col = point_colors, pch = 16, cex = 0.5,
xlab = "Observation", ylab = "y",
main = "Simulated Data with Quantile Estimates",
ylim = range(c(y, eta_linear)))
# Highlight the signal point with larger size
if (!is.na(signal_obs)) {
points(signal_obs, y[signal_obs], pch = 16, col = "darkgreen", cex = 1.5)
}
# Plot predictive quantiles with different colors
quantile_colors <- c("lightblue", "steelblue", "darkblue", "steelblue", "lightblue")
for (q in 1:length(taus)) {
lines(1:n, eta_linear[q, ], col = quantile_colors[q], lwd = 1.5)
}
# Add true shift line
abline(v = shift_start, col = "red", lwd = 2, lty = 2)
legend("topleft",
legend = c("Data", paste0("Q", taus), "True shift", "Signal (max dev)"),
col = c("gray50", quantile_colors, "red", "darkgreen"),
pch = c(16, rep(NA, length(taus)), NA, 16),
lty = c(NA, rep(1, length(taus)), 2, NA),
lwd = c(NA, rep(1.5, length(taus)), 2, NA),
bty = "n", cex = 0.7)
# Plot 2: Block-level p-values (barplot)
bar_colors <- ifelse(df$significant_bh, "red", "gray70")
neg_log_p <- -log10(pmax(df$pvalue_posterior, 1e-16))  # clamp to avoid -log10(0) = Inf
bp <- barplot(neg_log_p, names.arg = df$h_col,
col = bar_colors,
xlab = "H Column (Block)", ylab = "-log10(p-value)",
main = "Block-Level P-Values (BH/FDR Method)")
abline(h = -log10(0.05), col = "blue", lty = 2, lwd = 2)
# Mark true shift block
shift_block_idx <- which(df$obs_start <= shift_start & df$obs_end >= shift_start)
if (length(shift_block_idx) > 0) {
abline(v = bp[shift_block_idx[1]], col = "purple", lty = 3, lwd = 2)
}
legend("topright",
legend = c("Significant (BH)", "Not significant", "alpha = 0.05", "True shift"),
fill = c("red", "gray70", NA, NA),
border = c("black", "black", NA, NA),
lty = c(NA, NA, 2, 3), col = c(NA, NA, "blue", "purple"),
bty = "n", cex = 0.7)
# Plot 3: Box plot of decorrelated gamma L2 norm by block
# Uses whitened gamma (gamma_tilde) to remove posterior correlations between blocks
shift_block <- which(df$obs_start <= shift_start & df$obs_end >= shift_start)
if (length(shift_block) == 0) shift_block <- which(df$obs_start >= shift_start)[1]
box_colors <- rep("lightblue", r)
box_colors[shift_block] <- "salmon"
if (any(df$significant_bh)) {
box_colors[df$significant_bh] <- "red"
}
# Compute L2 norm from DECORRELATED gamma (gamma_tilde), not raw gamma
# gamma_tilde has shape (n_iter x m x r), same as gamma_samples
gamma_tilde <- gamma_result$gamma_tilde
gamma_by_block <- lapply(1:r, function(j) {
apply(gamma_tilde[, , j], 1, function(x) sqrt(sum(x^2)))
})
names(gamma_by_block) <- paste0("B", 1:r)
boxplot(gamma_by_block, col = box_colors,
xlab = "Block", ylab = "Decorrelated Gamma L2 Norm",
main = "Box Plot: Decorrelated Gamma by Block",
outline = FALSE)
legend("topleft", legend = c("Non-shift block", "Shift block (detected)", "True shift block"),
fill = c("lightblue", "red", "salmon"), bty = "n", cex = 0.8)
# Plot 4: Posterior p-values
barplot(1 - df$pvalue_posterior, names.arg = df$h_col,
col = ifelse(df$significant_bh, "red", "gray70"),
xlab = "H Column (Block)", ylab = "1 - Bayesian P-value",
main = "Bayesian P-values (1 - p)",
ylim = c(0, 1))
abline(h = 0.95, col = "blue", lty = 2, lwd = 2)
legend("topleft", legend = c("Significant (BH adj.)", "Threshold (0.05)"),
fill = c("red", NA), border = c("black", NA),
lty = c(NA, 2), col = c(NA, "blue"), bty = "n", cex = 0.8)
#dev.off()
#cat("Main results saved to: inference_iq_v4_results.pdf\n")
# =============================================================================
# QSS Statistics PDF (separate)
# =============================================================================
#pdf("inference_iq_v4_qss.pdf", width = 14, height = 10)
par(mfrow = c(2, 2), mar = c(4, 4, 2.5, 1))
# Compute QSS from MAP estimates (eta_linear) and 95% credible intervals from posterior
# MAP-based QSS (4 x n): Location, Scale, Skewness, Kurtosis
qss_map <- matrix(NA, 4, n)
rownames(qss_map) <- c("Location", "Scale", "Skewness", "Kurtosis")
qss_map[1, ] <- eta_linear[3, ]                                      # Median (tau = 0.5)
qss_map[2, ] <- eta_linear[4, ] - eta_linear[2, ]                    # IQR (Q75 - Q25)
iqr_map <- qss_map[2, ]
qss_map[3, ] <- ifelse(abs(iqr_map) > 1e-10,
((eta_linear[4, ] - eta_linear[3, ]) - (eta_linear[3, ] - eta_linear[2, ])) / iqr_map, 0)
qss_map[4, ] <- ifelse(abs(iqr_map) > 1e-10,
(eta_linear[5, ] - eta_linear[1, ]) / iqr_map, NA)
# 95% credible intervals from posterior QSS samples
qss_lo <- apply(qss, c(2, 3), quantile, 0.025)  # 2.5th percentile
qss_hi <- apply(qss, c(2, 3), quantile, 0.975)  # 97.5th percentile
obs_idx <- (w+1):n
# Helper: plot QSS with 95% credible band
plot_qss_ci <- function(k, ylab_text, main_text, line_col, band_col, add_hline = FALSE) {
ylim_range <- range(c(qss_lo[k, obs_idx], qss_hi[k, obs_idx]), na.rm = TRUE)
plot(obs_idx, qss_map[k, obs_idx], type = "n",
xlab = "Observation", ylab = ylab_text, main = main_text,
ylim = ylim_range)
polygon(c(obs_idx, rev(obs_idx)),
c(qss_lo[k, obs_idx], rev(qss_hi[k, obs_idx])),
col = band_col, border = NA)
lines(obs_idx, qss_map[k, obs_idx], col = line_col, lwd = 1.5)
abline(v = shift_start, col = "red", lwd = 2, lty = 2)
if (add_hline) abline(h = 0, col = "gray70", lty = 3)
legend("topleft",
legend = c("MAP estimate", "95% CI", "True shift"),
col = c(line_col, NA, "red"),
fill = c(NA, band_col, NA),
border = c(NA, NA, NA),
lty = c(1, NA, 2), lwd = c(1.5, NA, 2),
bty = "n", cex = 0.7)
}
# Plot 1: QSS - Location (Median)
plot_qss_ci(1, "Location (Median)", "QSS: Location",
"blue", adjustcolor("blue", alpha.f = 0.2), add_hline = TRUE)
# Plot 2: QSS - Scale (IQR)
plot_qss_ci(2, "Scale (IQR)", "QSS: Scale",
"darkgreen", adjustcolor("darkgreen", alpha.f = 0.2))
# Plot 3: QSS - Skewness (Bowley)
plot_qss_ci(3, "Skewness (Bowley)", "QSS: Skewness",
"purple", adjustcolor("purple", alpha.f = 0.2), add_hline = TRUE)
# Plot 4: QSS - Kurtosis (Tail Ratio)
plot_qss_ci(4, "Kurtosis (Tail Ratio)", "QSS: Kurtosis",
"orange", adjustcolor("orange", alpha.f = 0.2))
#dev.off()
#cat("QSS results saved to: inference_iq_v4_qss.pdf\n\n")
# =============================================================================
# Comparison PDF: BQQ vs cpt.meanvar
# =============================================================================
cat("Generating comparison plot: BQQ vs cpt.meanvar...\n")
# Load changepoint package
library(changepoint)
# Run cpt.meanvar with Asymptotic penalty
cpt_result <- cpt.meanvar(y, penalty = "Asymptotic", pen.value = 0.05, method = "PELT")
cpt_locations <- cpts(cpt_result)
cat("  cpt.meanvar detected change points:",
ifelse(length(cpt_locations) == 0, "None", paste(cpt_locations, collapse = ", ")), "\n")
#pdf("inference_iq_v4_comparison.pdf", width = 14, height = 6)
par(mfrow = c(1, 2), mar = c(4, 4, 2.5, 1))
# Panel 1: BQQ Method
# Recompute signal_obs for clarity
df_gamma <- gamma_result$detected_blocks
sig_blocks <- which(df_gamma$significant_bh)
signal_obs_bqq <- NA
if (length(sig_blocks) > 0) {
first_sig_block <- sig_blocks[1]
block_start <- df_gamma$obs_start[first_sig_block]
block_end <- df_gamma$obs_end[first_sig_block]
block_obs <- block_start:block_end
# Get gamma for this block to determine sign
gamma_block <- gamma_samples[, , first_sig_block]
gamma_mean <- mean(gamma_block)
gamma_sign <- sign(gamma_mean)
# Compute residuals (not absolute)
median_idx <- which.min(abs(taus - 0.5))
residuals <- y[block_obs] - eta_linear[median_idx, block_obs]
# Filter based on gamma sign
if (gamma_sign > 0) {
valid_idx <- which(residuals > 0)
} else if (gamma_sign < 0) {
valid_idx <- which(residuals < 0)
} else {
valid_idx <- seq_along(residuals)
}
if (length(valid_idx) > 0) {
deviations <- abs(residuals[valid_idx])
max_dev_idx <- valid_idx[which.max(deviations)]
signal_obs_bqq <- block_obs[max_dev_idx]
}
}
# Set up point colors for BQQ plot
point_colors_bqq <- rep("gray50", n)
if (!is.na(signal_obs_bqq)) {
point_colors_bqq[signal_obs_bqq] <- "darkgreen"
}
plot(1:n, y, type = "p", col = point_colors_bqq, pch = 16, cex = 0.5,
xlab = "Observation", ylab = "y",
main = "BQQ Method (Data-Adaptive Penalties, BH/FDR alpha = 0.05)",
ylim = range(c(y, eta_linear)))
# Highlight the signal point
if (!is.na(signal_obs_bqq)) {
points(signal_obs_bqq, y[signal_obs_bqq], pch = 16, col = "darkgreen", cex = 1.5)
}
# Plot predictive quantiles
quantile_colors <- c("lightblue", "steelblue", "darkblue", "steelblue", "lightblue")
for (q in 1:length(taus)) {
lines(1:n, eta_linear[q, ], col = quantile_colors[q], lwd = 1.5)
}
# Add true shift line
abline(v = shift_start, col = "red", lwd = 2, lty = 2)
legend("topleft",
legend = c("Data", paste0("Q", taus), "True shift", "Signal (max dev)"),
col = c("gray50", quantile_colors, "red", "darkgreen"),
pch = c(16, rep(NA, length(taus)), NA, 16),
lty = c(NA, rep(1, length(taus)), 2, NA),
lwd = c(NA, rep(1.5, length(taus)), 2, NA),
bty = "n", cex = 0.7)
# Panel 2: cpt.meanvar Method
plot(1:n, y, type = "p", col = "gray50", pch = 16, cex = 0.5,
xlab = "Observation", ylab = "y",
main = "cpt.meanvar (Asymptotic, pen.value = 0.05)",
ylim = range(y))
# Add detected change points from cpt.meanvar
if (length(cpt_locations) > 0) {
for (cp in cpt_locations) {
abline(v = cp, col = "blue", lwd = 2, lty = 1)
}
}
# Add true shift line
abline(v = shift_start, col = "red", lwd = 2, lty = 2)
# Add segment means
seg_starts <- c(1, cpt_locations + 1)
seg_ends <- c(cpt_locations, n)
for (i in seq_along(seg_starts)) {
seg_mean <- mean(y[seg_starts[i]:seg_ends[i]])
segments(seg_starts[i], seg_mean, seg_ends[i], seg_mean, col = "blue", lwd = 2)
}
legend("topleft",
legend = c("Data", "True shift", "Detected CP", "Segment mean"),
col = c("gray50", "red", "blue", "blue"),
pch = c(16, NA, NA, NA),
lty = c(NA, 2, 1, 1),
lwd = c(NA, 2, 2, 2),
bty = "n", cex = 0.8)
#dev.off()
#cat("Comparison plot saved to: inference_iq_v4_comparison.pdf\n\n")
# =============================================================================
# Debiased Two-Stage Testing PDF
# =============================================================================
cat("Generating debiased two-stage testing visualization...\n")
#pdf("inference_iq_v4_debiased.pdf", width = 14, height = 10)
par(mfrow = c(2, 2), mar = c(4, 4, 2.5, 1))
# Panel 1: Block-level chi-squared statistics (-log10 p-value scale)
shift_block_idx <- which(df$obs_start <= shift_start & df$obs_end >= shift_start)
neg_log_block_p <- -log10(pmax(block_adjp, 1e-16))
neg_log_block_p[!is.finite(neg_log_block_p)] <- 0
bar_colors_chi <- ifelse(!is.na(block_adjp) & block_adjp < 0.05, "red", "gray70")
bp_chi <- barplot(neg_log_block_p, names.arg = 1:r,
col = bar_colors_chi,
xlab = "Block", ylab = "-log10(BY-adj p-value)",
main = "Stage 1: Block-Level Chi-Squared Test (Mitra & Zhang 2016)")
abline(h = -log10(0.05), col = "blue", lty = 2, lwd = 2)
if (length(shift_block_idx) > 0) {
abline(v = bp_chi[shift_block_idx[1]], col = "purple", lty = 3, lwd = 2)
}
legend("topleft",
legend = c("Significant (BY)", "Not significant", "alpha = 0.05", "True shift block"),
fill = c("red", "gray70", NA, NA),
border = c("black", "black", NA, NA),
lty = c(NA, NA, 2, 3), col = c(NA, NA, "blue", "purple"),
bty = "n", cex = 0.7)
# Panel 2: Z-score heatmap across quantiles and blocks
z_plot <- z_mat
z_lim <- max(abs(z_mat), na.rm = TRUE)
n_colors <- 50
blue_white_red <- colorRampPalette(c("steelblue", "white", "tomato"))(n_colors)
image(1:r, 1:m, t(z_plot), col = blue_white_red, zlim = c(-z_lim, z_lim),
xlab = "Block", ylab = "Quantile",
main = "Z-Scores from Debiased Gamma (per quantile x block)",
axes = FALSE)
axis(1, at = 1:r, labels = 1:r)
axis(2, at = 1:m, labels = paste0("tau=", taus), las = 1)
box()
# Mark significant cells (per-element, alpha=0.05)
for (j in 1:r) {
for (q in 1:m) {
if (pval_element[q, j] < 0.05) {
points(j, q, pch = 8, cex = 1.0, col = "black")
}
}
}
# Mark Stage 1 significant blocks
if (length(sig_blocks_debiased) > 0) {
for (jj in sig_blocks_debiased) {
rect(jj - 0.5, 0.5, jj + 0.5, m + 0.5, border = "gold", lwd = 2)
}
}
if (length(shift_block_idx) > 0) {
abline(v = shift_block_idx[1], col = "purple", lty = 3, lwd = 2)
}
legend("topleft",
legend = c("Sig. element (p<0.05)", "Sig. block (Stage 1)", "True shift block"),
pch = c(8, NA, NA), lty = c(NA, 1, 3),
col = c("black", "gold", "purple"), lwd = c(NA, 2, 2),
bty = "n", cex = 0.65)
# Panel 3: MAP vs Debiased gamma for significant blocks (or last 3 blocks)
show_blocks <- if (length(sig_blocks_debiased) > 0) sig_blocks_debiased else max(1, r-2):r
n_show <- length(show_blocks)
# Grouped barplot: MAP and Debiased side by side per quantile
plot_data <- matrix(NA, nrow = 2 * m, ncol = n_show)
colnames(plot_data) <- paste0("B", show_blocks)
row_labels <- rep(paste0("tau=", taus), each = 2)
for (idx in seq_along(show_blocks)) {
j <- show_blocks[idx]
for (q in 1:m) {
plot_data[2 * (q - 1) + 1, idx] <- gamma_MAP[q, j]
plot_data[2 * (q - 1) + 2, idx] <- gamma_debiased[q, j]
}
}
pair_colors <- rep(c("gray70", "tomato"), m)
ylim_gam <- range(c(plot_data[is.finite(plot_data)], 0)) * 1.2
if (diff(ylim_gam) < 1e-10) ylim_gam <- c(-0.5, 0.5)
bp_gam <- barplot(plot_data, beside = TRUE, col = pair_colors,
xlab = "Block", ylab = "Gamma coefficient",
main = "MAP vs Debiased Gamma (Significant Blocks)",
ylim = ylim_gam)
abline(h = 0, col = "black", lty = 1, lwd = 0.5)
legend("topleft",
legend = c("MAP (shrunk)", "Debiased"),
fill = c("gray70", "tomato"),
bty = "n", cex = 0.7)
# Panel 4: Stage 2 â€” per-quantile z-scores for first significant block
if (length(sig_blocks_debiased) > 0) {
j <- sig_blocks_debiased[1]
res <- debiased_results[[as.character(j)]]
z_vals <- res$z_scores
z_cols <- ifelse(res$pval < 0.05 & z_vals > 0, "tomato",
ifelse(res$pval < 0.05 & z_vals < 0, "steelblue", "gray70"))
bp_z <- barplot(z_vals, names.arg = paste0("tau=", taus),
col = z_cols,
xlab = "Quantile", ylab = "Z-score",
main = paste0("Stage 2: Block ", j, " (",
res$shift_type, " shift)"))
abline(h = c(-1.96, 1.96), col = "blue", lty = 2, lwd = 1.5)
abline(h = 0, col = "black", lty = 1, lwd = 0.5)
legend("topleft",
legend = c("Sig. positive", "Sig. negative", "Not sig.", "+/- 1.96"),
fill = c("tomato", "steelblue", "gray70", NA),
border = c("black", "black", "black", NA),
lty = c(NA, NA, NA, 2), col = c(NA, NA, NA, "blue"),
bty = "n", cex = 0.7)
} else {
plot.new()
text(0.5, 0.5, "No significant blocks detected\nat Stage 1",
cex = 1.5, col = "gray50")
}
#dev.off()
#cat("Debiased testing results saved to: inference_iq_v4_debiased.pdf\n\n")
# =============================================================================
# PART 9: Summary
# =============================================================================
cat("=== PART 9: Summary ===\n\n")
cat("Data-Adaptive Penalties Summary:\n")
cat("--------------------------------\n")
cat("True shift point:", shift_start, "\n")
cat("Warm-up period:", w, "\n")
cat("Block length:", l, "\n")
cat("Number of H columns (gamma per quantile):", r, "\n")
cat("Number of quantiles:", m, "\n")
cat("Total gamma parameters:", m * r, "\n\n")
cat("Penalty Settings (all from CV):\n")
cat("  adaptive_gamma = TRUE, lambda_lasso2 ~ Gamma(1,", best_lambda_lasso2_b, ")\n")
cat("  adaptive_iq = TRUE, lambda_iq2 ~ Gamma(1,", best_lambda_iq2_b, ")\n")
cat("  lambda_nc =", best_lambda_nc, "\n\n")
cat("Cross-Validation Results:\n")
cat("  Grid: lambda_nc x lambda_lasso2_b x lambda_iq2_b =",
nrow(cv_grid), "combinations\n")
cat("  Best lambda_nc:", best_lambda_nc, "\n")
cat("  Best lambda_lasso2_b:", best_lambda_lasso2_b, "\n")
cat("  Best lambda_iq2_b:", best_lambda_iq2_b, "\n")
cat("  Best validation loss:", round(cv_result$val_loss[1], 4), "\n\n")
cat("Detection Performance:\n")
cat("  [Bayesian decorrelation (BH)]:\n")
cat("    Significant blocks:", gamma_result$n_significant_bh, "\n")
cat("    Signal observation (max deviation):",
ifelse(is.na(signal_obs_bqq), "None", signal_obs_bqq), "\n")
if (!is.na(signal_obs_bqq)) {
cat("    Detection delay:", signal_obs_bqq - shift_start, "observations\n")
}
cat("  [Debiased chi-squared + BY (Mitra & Zhang 2016)]:\n")
cat("    Significant blocks:", length(sig_blocks_debiased), "\n")
if (length(sig_blocks_debiased) > 0) {
cat("    Block indices:", paste(sig_blocks_debiased, collapse = ", "), "\n")
for (j_str in names(debiased_results)) {
res <- debiased_results[[j_str]]
cat(sprintf("    Block %d: %s shift (Chi-sq=%.2f, BY-adj p=%.4f)\n",
res$block, res$shift_type, res$chisq, res$block_adjp))
}
}
cat("\n")
# =============================================================================
# Sensitivity and Specificity Calculation
# =============================================================================
# Using symmetric window for both BQQ and cpt.meanvar:
# - Tolerance = block length (l)
# - TP: detection within [shift_start - tolerance, shift_start + tolerance]
# - FP: detection outside this window
tolerance <- l  # use block length as tolerance
# For BQQ: use signal_obs_bqq as the detected change point
if (!is.na(signal_obs_bqq)) {
# True Positive: signal observation is within tolerance of true shift
TP_bqq <- abs(signal_obs_bqq - shift_start) <= tolerance
# False Positive: signal observation is outside tolerance
FP_bqq <- !TP_bqq
sensitivity_bqq <- if (TP_bqq) 1.0 else 0.0
specificity_bqq <- if (TP_bqq) 1.0 else 0.0  # No FP if detection is correct
} else {
# No detection
TP_bqq <- FALSE
FP_bqq <- FALSE
sensitivity_bqq <- 0.0
specificity_bqq <- 1.0  # No false alarms if no detections
}
cat("Sensitivity and Specificity (BQQ Method):\n")
cat("  Signal observation:", ifelse(is.na(signal_obs_bqq), "None", signal_obs_bqq), "\n")
cat("  True shift:", shift_start, "\n")
cat("  Tolerance (block length):", tolerance, "\n")
cat("  Window: [", shift_start - tolerance, ",", shift_start + tolerance, "]\n")
cat("  True Positive (detection within tolerance):", TP_bqq, "\n")
cat("  False Positive (detection outside tolerance):", FP_bqq, "\n")
cat("  Sensitivity:", round(sensitivity_bqq, 4), "\n")
cat("  Specificity:", round(specificity_bqq, 4), "\n\n")
# For cpt.meanvar: consider a detection "correct" if within block_length of true shift
tolerance <- l  # use block length as tolerance
if (length(cpt_locations) > 0) {
# True Positive: at least one detected CP is within tolerance of true shift
TP_cpt <- any(abs(cpt_locations - shift_start) <= tolerance)
# False Positives: detected CPs that are NOT within tolerance of true shift
FP_cpt <- sum(abs(cpt_locations - shift_start) > tolerance)
sensitivity_cpt <- if (TP_cpt) 1.0 else 0.0
# For specificity, we use: 1 - (FP / total detections) as a proxy
specificity_cpt <- if (length(cpt_locations) > 0) 1 - FP_cpt / length(cpt_locations) else 1.0
} else {
sensitivity_cpt <- 0.0
specificity_cpt <- 1.0  # No false alarms if no detections
TP_cpt <- FALSE
FP_cpt <- 0
}
cat("Sensitivity and Specificity (cpt.meanvar):\n")
cat("  Detected change points:", ifelse(length(cpt_locations) == 0, "None", paste(cpt_locations, collapse = ", ")), "\n")
cat("  True shift:", shift_start, "\n")
cat("  Tolerance (block length):", tolerance, "\n")
cat("  True Positive (detection within tolerance):", TP_cpt, "\n")
cat("  False Positives (detections outside tolerance):", FP_cpt, "\n")
cat("  Sensitivity:", round(sensitivity_cpt, 4), "\n")
cat("  Specificity:", round(specificity_cpt, 4), "\n\n")
cat("Decorrelation Effectiveness:\n")
cat("  Max correlation before whitening:", round(max(abs(cor_orig[lower.tri(cor_orig)])), 4), "\n")
cat("  Max correlation after whitening:", round(max(abs(cor_decor[lower.tri(cor_decor)])), 4), "\n")
cat("\n================================================================\n")
cat("Data-Adaptive Penalties Example Complete!\n")
cat("================================================================\n")
